{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7101010",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Face Extraction Pipeline\n",
    "\n",
    "## Cross-Attention CNN Personality Trait Prediction Project\n",
    "\n",
    "This notebook extracts faces from existing frame data using GPU-accelerated MTCNN face detection, then computes optical flow sequences for the Cross-Attention CNN model.\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Verify GPU Support** - Ensure TensorFlow has GPU access\n",
    "2. **Extract Faces** - Use MTCNN on existing frames (82,620 frames from 960 videos)\n",
    "3. **Compute Optical Flow** - Generate flow sequences between consecutive face frames\n",
    "4. **Progress Tracking** - Monitor extraction progress and save results\n",
    "\n",
    "### Data Structure:\n",
    "- **Input**: `data/processed/frames/` (existing frame extractions)\n",
    "- **Output**: `data/processed/faces/` and `data/processed/optical_flow/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30c28cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "OpenCV version: 4.10.0\n",
      "NumPy version: 1.24.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import MTCNN for face detection\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b75eb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç GPU Configuration Check\n",
      "==================================================\n",
      "Physical GPUs: 1\n",
      "Logical GPUs: 1\n",
      "‚úÖ GPU Support Available!\n",
      "   GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "‚ö†Ô∏è Memory growth setup error: Physical devices cannot be modified after being initialized\n",
      "\n",
      "üß™ Test operation result: [[ 7. 10.]\n",
      " [15. 22.]]\n",
      "Device used: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU Availability and Configuration\n",
    "print(\"üîç GPU Configuration Check\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# List physical GPU devices\n",
    "physical_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "print(f\"Physical GPUs: {len(physical_gpus)}\")\n",
    "print(f\"Logical GPUs: {len(logical_gpus)}\")\n",
    "\n",
    "if physical_gpus:\n",
    "    print(\"‚úÖ GPU Support Available!\")\n",
    "    for i, gpu in enumerate(physical_gpus):\n",
    "        print(f\"   GPU {i}: {gpu}\")\n",
    "    \n",
    "    # Enable memory growth to prevent TensorFlow from allocating all GPU memory\n",
    "    try:\n",
    "        for gpu in physical_gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"‚úÖ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è Memory growth setup error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected - using CPU\")\n",
    "\n",
    "# Test GPU with a simple operation\n",
    "with tf.device('/GPU:0' if physical_gpus else '/CPU:0'):\n",
    "    test_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    result = tf.matmul(test_tensor, test_tensor)\n",
    "    print(f\"\\nüß™ Test operation result: {result.numpy()}\")\n",
    "    print(f\"Device used: {result.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23cce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing MTCNN Face Detector\n",
      "==================================================\n",
      "‚úÖ MTCNN detector initialized\n",
      "üìÅ Output directories created:\n",
      "   Faces: data/processed/faces\n",
      "   Optical Flow: data/processed/optical_flow\n"
     ]
    }
   ],
   "source": [
    "# Initialize MTCNN Face Detector\n",
    "print(\"ü§ñ Initializing MTCNN Face Detector\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize MTCNN with default settings (it will auto-optimize)\n",
    "detector = MTCNN()\n",
    "\n",
    "print(\"‚úÖ MTCNN detector initialized\")\n",
    "\n",
    "# Configuration\n",
    "target_face_size = (224, 224)\n",
    "frames_base_dir = 'data/processed/frames'\n",
    "faces_base_dir = 'data/processed/faces'\n",
    "flow_base_dir = 'data/processed/optical_flow'\n",
    "\n",
    "# Create output directories\n",
    "Path(faces_base_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(flow_base_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directories created:\")\n",
    "print(f\"   Faces: {faces_base_dir}\")\n",
    "print(f\"   Optical Flow: {flow_base_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e499dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Structure Analysis\n",
      "==================================================\n",
      "Found 12 training directories:\n",
      "   training80_01: 80 videos, 6971 frames\n",
      "   training80_02: 80 videos, 6874 frames\n",
      "   training80_03: 80 videos, 6666 frames\n",
      "   training80_04: 80 videos, 6858 frames\n",
      "   training80_05: 80 videos, 6971 frames\n",
      "   training80_06: 80 videos, 6861 frames\n",
      "   training80_07: 80 videos, 6897 frames\n",
      "   training80_08: 80 videos, 7060 frames\n",
      "   training80_09: 80 videos, 6920 frames\n",
      "   training80_10: 80 videos, 6738 frames\n",
      "   training80_11: 80 videos, 6959 frames\n",
      "   training80_12: 80 videos, 6845 frames\n",
      "\n",
      "üìà Summary:\n",
      "   Total training directories: 12\n",
      "   Total videos: 960\n",
      "   Total frames: 82,620\n"
     ]
    }
   ],
   "source": [
    "# Analyze Current Data Structure\n",
    "print(\"üìä Data Structure Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check frames directory structure\n",
    "if os.path.exists(frames_base_dir):\n",
    "    training_dirs = sorted([d for d in os.listdir(frames_base_dir) \n",
    "                           if os.path.isdir(os.path.join(frames_base_dir, d))])\n",
    "    \n",
    "    total_videos = 0\n",
    "    total_frames = 0\n",
    "    frame_stats = {}\n",
    "    \n",
    "    print(f\"Found {len(training_dirs)} training directories:\")\n",
    "    \n",
    "    for training_dir in training_dirs:\n",
    "        training_path = os.path.join(frames_base_dir, training_dir)\n",
    "        video_dirs = [d for d in os.listdir(training_path) \n",
    "                     if os.path.isdir(os.path.join(training_path, d))]\n",
    "        \n",
    "        dir_frames = 0\n",
    "        for video_dir in video_dirs:\n",
    "            video_path = os.path.join(training_path, video_dir)\n",
    "            frame_files = [f for f in os.listdir(video_path) if f.endswith('.jpg')]\n",
    "            dir_frames += len(frame_files)\n",
    "        \n",
    "        total_videos += len(video_dirs)\n",
    "        total_frames += dir_frames\n",
    "        frame_stats[training_dir] = {\n",
    "            'videos': len(video_dirs),\n",
    "            'frames': dir_frames\n",
    "        }\n",
    "        \n",
    "        print(f\"   {training_dir}: {len(video_dirs)} videos, {dir_frames} frames\")\n",
    "    \n",
    "    print(f\"\\nüìà Summary:\")\n",
    "    print(f\"   Total training directories: {len(training_dirs)}\")\n",
    "    print(f\"   Total videos: {total_videos}\")\n",
    "    print(f\"   Total frames: {total_frames:,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Frames directory not found!\")\n",
    "    frame_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aafcb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Face extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "# Face Extraction Functions\n",
    "def extract_face_from_frame(frame_path, detector, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extract face from a single frame using MTCNN\n",
    "    \n",
    "    Args:\n",
    "        frame_path: Path to the frame image\n",
    "        detector: MTCNN detector instance\n",
    "        target_size: Target size for face image\n",
    "    \n",
    "    Returns:\n",
    "        face_img: Processed face image or None if no face found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        image = cv2.imread(frame_path)\n",
    "        if image is None:\n",
    "            return None\n",
    "            \n",
    "        # Convert BGR to RGB for MTCNN\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        result = detector.detect_faces(rgb_image)\n",
    "        \n",
    "        if result:\n",
    "            # Use the first (most confident) face\n",
    "            face = result[0]\n",
    "            x, y, width, height = face['box']\n",
    "            \n",
    "            # Add padding and ensure bounds\n",
    "            padding = 20\n",
    "            x = max(0, x - padding)\n",
    "            y = max(0, y - padding)\n",
    "            width = min(rgb_image.shape[1] - x, width + 2*padding)\n",
    "            height = min(rgb_image.shape[0] - y, height + 2*padding)\n",
    "            \n",
    "            # Extract face region\n",
    "            face_img = rgb_image[y:y+height, x:x+width]\n",
    "            \n",
    "            # Resize to target size\n",
    "            face_resized = cv2.resize(face_img, target_size)\n",
    "            \n",
    "            # Convert back to BGR for saving\n",
    "            face_bgr = cv2.cvtColor(face_resized, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            return face_bgr\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {frame_path}: {e}\")\n",
    "        \n",
    "    return None\n",
    "\n",
    "def extract_faces_from_video_directory(video_frames_dir, video_faces_dir, detector):\n",
    "    \"\"\"\n",
    "    Extract faces from all frames in a single video directory\n",
    "    \"\"\"\n",
    "    Path(video_faces_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    frame_files = sorted([f for f in os.listdir(video_frames_dir) if f.endswith('.jpg')])\n",
    "    extracted_count = 0\n",
    "    \n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(video_frames_dir, frame_file)\n",
    "        face_img = extract_face_from_frame(frame_path, detector, target_face_size)\n",
    "        \n",
    "        if face_img is not None:\n",
    "            face_filename = f\"face_{os.path.splitext(frame_file)[0]}.jpg\"\n",
    "            face_path = os.path.join(video_faces_dir, face_filename)\n",
    "            cv2.imwrite(face_path, face_img)\n",
    "            extracted_count += 1\n",
    "            \n",
    "    return extracted_count\n",
    "\n",
    "print(\"‚úÖ Face extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting GPU-Accelerated Face Extraction Pipeline\n",
      "============================================================\n",
      "Processing 12 training directories...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327e7ea4515b4856a0a36b629e1b506f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Directories:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cdf1b51054407e8bc75afa2febcd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_01 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ training80_01: 6966 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3b9d0dc3a74ed09a5b86b92c1cfb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_02 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main Face Extraction Pipeline\n",
    "print(\"üöÄ Starting GPU-Accelerated Face Extraction Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "extraction_stats = {\n",
    "    'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'gpu_available': len(tf.config.experimental.list_logical_devices('GPU')) > 0,\n",
    "    'training_directories': {},\n",
    "    'total_faces': 0,\n",
    "    'total_videos_processed': 0,\n",
    "    'failed_videos': []\n",
    "}\n",
    "\n",
    "if os.path.exists(frames_base_dir):\n",
    "    training_dirs = sorted([d for d in os.listdir(frames_base_dir) \n",
    "                           if os.path.isdir(os.path.join(frames_base_dir, d))])\n",
    "    \n",
    "    print(f\"Processing {len(training_dirs)} training directories...\")\n",
    "    \n",
    "    # Process each training directory\n",
    "    for training_dir in tqdm(training_dirs, desc=\"Training Directories\"):\n",
    "        training_frames_path = os.path.join(frames_base_dir, training_dir)\n",
    "        training_faces_path = os.path.join(faces_base_dir, training_dir)\n",
    "        \n",
    "        # Get all video directories\n",
    "        video_dirs = sorted([d for d in os.listdir(training_frames_path) \n",
    "                           if os.path.isdir(os.path.join(training_frames_path, d))])\n",
    "        \n",
    "        training_faces = 0\n",
    "        training_failed = 0\n",
    "        \n",
    "        # Process each video directory\n",
    "        for video_dir in tqdm(video_dirs, desc=f\"{training_dir} videos\", leave=False):\n",
    "            video_frames_path = os.path.join(training_frames_path, video_dir)\n",
    "            video_faces_path = os.path.join(training_faces_path, video_dir)\n",
    "            \n",
    "            try:\n",
    "                extracted = extract_faces_from_video_directory(\n",
    "                    video_frames_path, video_faces_path, detector\n",
    "                )\n",
    "                \n",
    "                if extracted > 0:\n",
    "                    training_faces += extracted\n",
    "                    extraction_stats['total_videos_processed'] += 1\n",
    "                else:\n",
    "                    training_failed += 1\n",
    "                    extraction_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {training_dir}/{video_dir}: {e}\")\n",
    "                training_failed += 1\n",
    "                extraction_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "        \n",
    "        # Store training directory stats\n",
    "        extraction_stats['training_directories'][training_dir] = {\n",
    "            'videos_processed': len(video_dirs) - training_failed,\n",
    "            'videos_failed': training_failed,\n",
    "            'faces_extracted': training_faces\n",
    "        }\n",
    "        \n",
    "        extraction_stats['total_faces'] += training_faces\n",
    "        \n",
    "        print(f\"‚úÖ {training_dir}: {training_faces} faces from {len(video_dirs)} videos\")\n",
    "    \n",
    "    # Calculate processing time\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    extraction_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    extraction_stats['processing_time_seconds'] = processing_time\n",
    "    extraction_stats['processing_time_formatted'] = str(time.strftime('%H:%M:%S', time.gmtime(processing_time)))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üéâ FACE EXTRACTION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚è±Ô∏è  Processing time: {extraction_stats['processing_time_formatted']}\")\n",
    "    print(f\"üòä Total faces extracted: {extraction_stats['total_faces']:,}\")\n",
    "    print(f\"üìÅ Videos processed: {extraction_stats['total_videos_processed']}\")\n",
    "    print(f\"‚ùå Failed videos: {len(extraction_stats['failed_videos'])}\")\n",
    "    print(f\"üéØ GPU acceleration: {'‚úÖ Enabled' if extraction_stats['gpu_available'] else '‚ùå Disabled'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Frames directory not found!\")\n",
    "    extraction_stats['error'] = 'Frames directory not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec19c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Extraction Results\n",
    "results_file = 'results/face_extraction_results.json'\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(extraction_stats, f, indent=2)\n",
    "\n",
    "print(f\"üìä Results saved to: {results_file}\")\n",
    "\n",
    "# Display detailed statistics\n",
    "print(\"\\nüìà Detailed Statistics:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'training_directories' in extraction_stats:\n",
    "    for training_dir, stats in extraction_stats['training_directories'].items():\n",
    "        success_rate = (stats['videos_processed'] / (stats['videos_processed'] + stats['videos_failed'])) * 100 if (stats['videos_processed'] + stats['videos_failed']) > 0 else 0\n",
    "        print(f\"{training_dir}:\")\n",
    "        print(f\"  Faces: {stats['faces_extracted']:,}\")\n",
    "        print(f\"  Videos: {stats['videos_processed']}/{stats['videos_processed'] + stats['videos_failed']} ({success_rate:.1f}% success)\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396daa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical Flow Computation Functions\n",
    "def compute_optical_flow_for_video(faces_dir, flow_dir):\n",
    "    \"\"\"\n",
    "    Compute optical flow for a sequence of face images in one video\n",
    "    \n",
    "    Args:\n",
    "        faces_dir: Directory containing face images\n",
    "        flow_dir: Directory to save optical flow files\n",
    "    \n",
    "    Returns:\n",
    "        Number of optical flow computations performed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Path(flow_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get all face images\n",
    "        face_files = sorted([f for f in os.listdir(faces_dir) if f.endswith('.jpg')])\n",
    "        \n",
    "        if len(face_files) < 2:\n",
    "            return 0\n",
    "        \n",
    "        flow_count = 0\n",
    "        \n",
    "        for i in range(len(face_files) - 1):\n",
    "            # Read consecutive frames\n",
    "            frame1_path = os.path.join(faces_dir, face_files[i])\n",
    "            frame2_path = os.path.join(faces_dir, face_files[i + 1])\n",
    "            \n",
    "            frame1 = cv2.imread(frame1_path, cv2.IMREAD_GRAYSCALE)\n",
    "            frame2 = cv2.imread(frame2_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if frame1 is not None and frame2 is not None:\n",
    "                # Compute optical flow using Farneback method\n",
    "                flow = cv2.calcOpticalFlowFarneback(\n",
    "                    frame1, frame2, None, \n",
    "                    pyr_scale=0.5, levels=3, winsize=15, \n",
    "                    iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "                )\n",
    "                \n",
    "                # Save optical flow as numpy array\n",
    "                flow_filename = f\"flow_{i:04d}_{i+1:04d}.npy\"\n",
    "                flow_path = os.path.join(flow_dir, flow_filename)\n",
    "                np.save(flow_path, flow)\n",
    "                flow_count += 1\n",
    "        \n",
    "        return flow_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing optical flow for {faces_dir}: {e}\")\n",
    "        return 0\n",
    "\n",
    "print(\"‚úÖ Optical flow functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical Flow Computation Pipeline\n",
    "print(\"üåä Starting Optical Flow Computation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "flow_start_time = time.time()\n",
    "flow_stats = {\n",
    "    'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_directories': {},\n",
    "    'total_flows': 0,\n",
    "    'total_videos_processed': 0,\n",
    "    'failed_videos': []\n",
    "}\n",
    "\n",
    "if os.path.exists(faces_base_dir):\n",
    "    training_dirs = sorted([d for d in os.listdir(faces_base_dir) \n",
    "                           if os.path.isdir(os.path.join(faces_base_dir, d))])\n",
    "    \n",
    "    print(f\"Computing optical flow for {len(training_dirs)} training directories...\")\n",
    "    \n",
    "    # Process each training directory\n",
    "    for training_dir in tqdm(training_dirs, desc=\"Computing Optical Flow\"):\n",
    "        training_faces_path = os.path.join(faces_base_dir, training_dir)\n",
    "        training_flow_path = os.path.join(flow_base_dir, training_dir)\n",
    "        \n",
    "        # Get all video directories\n",
    "        video_dirs = sorted([d for d in os.listdir(training_faces_path) \n",
    "                           if os.path.isdir(os.path.join(training_faces_path, d))])\n",
    "        \n",
    "        training_flows = 0\n",
    "        training_failed = 0\n",
    "        \n",
    "        # Process each video directory\n",
    "        for video_dir in tqdm(video_dirs, desc=f\"{training_dir} optical flow\", leave=False):\n",
    "            video_faces_path = os.path.join(training_faces_path, video_dir)\n",
    "            video_flow_path = os.path.join(training_flow_path, video_dir)\n",
    "            \n",
    "            try:\n",
    "                flow_count = compute_optical_flow_for_video(video_faces_path, video_flow_path)\n",
    "                \n",
    "                if flow_count > 0:\n",
    "                    training_flows += flow_count\n",
    "                    flow_stats['total_videos_processed'] += 1\n",
    "                else:\n",
    "                    training_failed += 1\n",
    "                    flow_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error computing optical flow for {training_dir}/{video_dir}: {e}\")\n",
    "                training_failed += 1\n",
    "                flow_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "        \n",
    "        # Store training directory stats\n",
    "        flow_stats['training_directories'][training_dir] = {\n",
    "            'videos_processed': len(video_dirs) - training_failed,\n",
    "            'videos_failed': training_failed,\n",
    "            'flows_computed': training_flows\n",
    "        }\n",
    "        \n",
    "        flow_stats['total_flows'] += training_flows\n",
    "        \n",
    "        print(f\"‚úÖ {training_dir}: {training_flows} optical flows from {len(video_dirs)} videos\")\n",
    "    \n",
    "    # Calculate processing time\n",
    "    flow_end_time = time.time()\n",
    "    flow_processing_time = flow_end_time - flow_start_time\n",
    "    flow_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    flow_stats['processing_time_seconds'] = flow_processing_time\n",
    "    flow_stats['processing_time_formatted'] = str(time.strftime('%H:%M:%S', time.gmtime(flow_processing_time)))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üéâ OPTICAL FLOW COMPUTATION COMPLETED!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚è±Ô∏è  Processing time: {flow_stats['processing_time_formatted']}\")\n",
    "    print(f\"üåä Total optical flows: {flow_stats['total_flows']:,}\")\n",
    "    print(f\"üìÅ Videos processed: {flow_stats['total_videos_processed']}\")\n",
    "    print(f\"‚ùå Failed videos: {len(flow_stats['failed_videos'])}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Faces directory not found! Please run face extraction first.\")\n",
    "    flow_stats['error'] = 'Faces directory not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Optical Flow Results\n",
    "flow_results_file = 'results/optical_flow_results.json'\n",
    "\n",
    "with open(flow_results_file, 'w') as f:\n",
    "    json.dump(flow_stats, f, indent=2)\n",
    "\n",
    "print(f\"üìä Optical flow results saved to: {flow_results_file}\")\n",
    "\n",
    "# Create Combined Pipeline Summary\n",
    "combined_stats = {\n",
    "    'pipeline_completion_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'gpu_acceleration': len(tf.config.experimental.list_logical_devices('GPU')) > 0,\n",
    "    'face_extraction': extraction_stats if 'extraction_stats' in locals() else {},\n",
    "    'optical_flow': flow_stats if 'flow_stats' in locals() else {}\n",
    "}\n",
    "\n",
    "combined_results_file = 'results/complete_preprocessing_results.json'\n",
    "with open(combined_results_file, 'w') as f:\n",
    "    json.dump(combined_stats, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìã Complete pipeline results saved to: {combined_results_file}\")\n",
    "\n",
    "# Display Final Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèÅ COMPLETE PREPROCESSING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'extraction_stats' in locals() and 'flow_stats' in locals():\n",
    "    total_pipeline_time = (extraction_stats.get('processing_time_seconds', 0) + \n",
    "                          flow_stats.get('processing_time_seconds', 0))\n",
    "    \n",
    "    print(f\"üìä Final Statistics:\")\n",
    "    print(f\"   ‚Ä¢ Total faces extracted: {extraction_stats.get('total_faces', 0):,}\")\n",
    "    print(f\"   ‚Ä¢ Total optical flows: {flow_stats.get('total_flows', 0):,}\")\n",
    "    print(f\"   ‚Ä¢ Videos processed: {extraction_stats.get('total_videos_processed', 0)}\")\n",
    "    print(f\"   ‚Ä¢ GPU acceleration: {'‚úÖ Enabled' if combined_stats['gpu_acceleration'] else '‚ùå Disabled'}\")\n",
    "    print(f\"   ‚Ä¢ Total pipeline time: {time.strftime('%H:%M:%S', time.gmtime(total_pipeline_time))}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Output Directories:\")\n",
    "    print(f\"   ‚Ä¢ Faces: {faces_base_dir}\")\n",
    "    print(f\"   ‚Ä¢ Optical Flow: {flow_base_dir}\")\n",
    "    print(f\"   ‚Ä¢ Results: results/\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Preprocessing pipeline completed successfully!\")\n",
    "    print(f\"   Ready for feature extraction and model training.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pipeline incomplete - check error messages above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Verification and Next Steps\n",
    "print(\"\\nüîç Data Verification\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Verify output structure\n",
    "verification_results = {\n",
    "    'faces_directory_exists': os.path.exists(faces_base_dir),\n",
    "    'optical_flow_directory_exists': os.path.exists(flow_base_dir),\n",
    "    'face_count': 0,\n",
    "    'flow_count': 0\n",
    "}\n",
    "\n",
    "if verification_results['faces_directory_exists']:\n",
    "    # Count total faces\n",
    "    for root, dirs, files in os.walk(faces_base_dir):\n",
    "        verification_results['face_count'] += len([f for f in files if f.endswith('.jpg')])\n",
    "\n",
    "if verification_results['optical_flow_directory_exists']:\n",
    "    # Count total optical flow files\n",
    "    for root, dirs, files in os.walk(flow_base_dir):\n",
    "        verification_results['flow_count'] += len([f for f in files if f.endswith('.npy')])\n",
    "\n",
    "print(f\"‚úÖ Verification Results:\")\n",
    "print(f\"   ‚Ä¢ Faces directory: {'‚úÖ' if verification_results['faces_directory_exists'] else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ Optical flow directory: {'‚úÖ' if verification_results['optical_flow_directory_exists'] else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ Total face images: {verification_results['face_count']:,}\")\n",
    "print(f\"   ‚Ä¢ Total optical flow files: {verification_results['flow_count']:,}\")\n",
    "\n",
    "# Next Steps\n",
    "print(f\"\\nüéØ Next Steps:\")\n",
    "print(f\"   1. Extract static features (ResNet-50 2D CNN) ‚Üí 512-dim features\")\n",
    "print(f\"   2. Extract dynamic features (I3D 3D CNN) ‚Üí 256-dim features\")\n",
    "print(f\"   3. Validate data alignment (960 samples)\")\n",
    "print(f\"   4. Begin Cross-Attention CNN model training\")\n",
    "print(f\"\\nüìñ Ready to proceed with feature extraction and training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
